{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数搜索与sklearn实现\n",
    "\n",
    "#### 参数类型\n",
    "\n",
    "* 一般参数：模型通过最小化损失函数自动求解的参数\n",
    "\n",
    "* 超参数：不能通过模型对数据进行学习而求解的参数，比如神经网络的层数、正则系数的alpha值等\n",
    "\n",
    "#### 参数搜索：\n",
    "* 超参数的搜索：提前设置好参数可以选择的候选值，然后根据不同参数组合对于模型泛化能力的贡献，选取最佳的超参数组合。\n",
    "\n",
    "#### 参数搜索的方法：\n",
    "\n",
    "GridSearchCV，基于交叉验证的网格搜索法：将要搜索的参数候选值输入搜索器内，搜索器遍历每一种参数组合，使用交叉验证法对比每种参数组合下模型的表现，返回表现最好模型的参数值\n",
    "\n",
    "- 优点：自动调参，参数准确性高\n",
    "\n",
    "- 缺点：需要耗费巨大的算例和计算时间（比如：搜索100颗树的随机森森模型的两种参数各三个候选值，选择k等于10的交叉验证，则需要训练验证9000颗决策树才能返回最佳参数）\n",
    "\n",
    "RandomizedSearchCV，基于交叉验证的随机搜索法：基本原理与GridSearchCV一致，但为了提高搜索效率，搜索器会从参数组合中随机搜索一些参数进行训练和验证，返回其中表现最好的参数值\n",
    "\n",
    "- 优点：运行效率高，适合大数据量样本\n",
    "\n",
    "- 缺点：参数的准确性有所牺牲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30273.0\n",
      "True     449\n",
      "False    449\n",
      "Name: is_high, dtype: int64\n",
      "(898, 10)\n",
      "id                 int64\n",
      "complete_year      int64\n",
      "average_price    float64\n",
      "area             float64\n",
      "daypop           float64\n",
      "sub_kde          float64\n",
      "bus_kde          float64\n",
      "kind_kde         float64\n",
      "per_a20_39       float64\n",
      "is_high             bool\n",
      "dtype: object\n",
      "id               0\n",
      "complete_year    0\n",
      "average_price    0\n",
      "area             0\n",
      "daypop           0\n",
      "sub_kde          0\n",
      "bus_kde          0\n",
      "kind_kde         0\n",
      "per_a20_39       0\n",
      "is_high          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# 样例数据读取\n",
    "df = pd.read_excel('realestate_sample_preprocessed.xlsx')\n",
    "# 根据共线性矩阵，保留与房价相关性最高的日间人口，将夜间人口和20-39岁夜间人口进行比例处理\n",
    "def age_percent(row):\n",
    "    if row['nightpop'] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return row['night20-39']/row['nightpop']\n",
    "df['per_a20_39'] = df.apply(age_percent,axis=1)\n",
    "df = df.drop(columns=['nightpop','night20-39'])\n",
    "# 制作标签变量\n",
    "price_median = df['average_price'].median()\n",
    "print(price_median)\n",
    "df['is_high'] = df['average_price'].map(lambda x: True if x>= price_median else False)\n",
    "print(df['is_high'].value_counts())\n",
    "# 数据集基本情况查看\n",
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of training set is: (673, 10)\n",
      "the shape of testing set is: (225, 10)\n"
     ]
    }
   ],
   "source": [
    "# 留出法进行数据集划分\n",
    "# 载入sklearn中数据集划分的方法\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 将数据集划分成训练集和验证集：划分比例0.75训练，0.25验证\n",
    "training, testing = train_test_split(df,test_size=0.25, random_state=1)\n",
    "# 提取训练集中的x与y\n",
    "x_train = training.copy()[['complete_year','area', 'daypop', 'sub_kde',\n",
    "       'bus_kde', 'kind_kde','per_a20_39']]\n",
    "y_train = training.copy()['is_high']\n",
    "# 提取验证集中的x与y\n",
    "x_test = testing.copy()[['complete_year','area', 'daypop', 'sub_kde',\n",
    "       'bus_kde', 'kind_kde','per_a20_39']]\n",
    "y_test = testing.copy()['is_high']\n",
    "print(f'the shape of training set is: {training.shape}')\n",
    "print(f'the shape of testing set is: {testing.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('sc', StandardScaler(copy=True, with_mean=True, with_std=True)), ('power_trans', PowerTransformer(copy=True, method='yeo-johnson', standardize=True)), ('polynom_trans', PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), ('rf_clf', GridSearchCV(cv=StratifiedKFold(n_spli...e_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring='roc_auc', verbose=2))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer, StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "# 如果是选择随机网格搜索则：\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "# 定义随机森林模型\n",
    "rf_model = RandomForestClassifier(criterion='gini',\n",
    "                                  n_jobs=16,\n",
    "                                  n_estimators = 100,\n",
    "                                  random_state=133)\n",
    "# 定义需要搜索的参数矩阵\n",
    "parameters = {'max_features': ['auto',5, 0.8, None],\n",
    "              'max_depth': [None, 3, 9]}\n",
    "# 定义交叉验证机制    \n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "# 定义参数搜索器\n",
    "rf_gridsearch = GridSearchCV(rf_model, parameters, n_jobs=16, cv=cv, scoring='roc_auc',\n",
    "                                      verbose=2, refit=True)\n",
    "# pipline 模型封装\n",
    "pipe_clf = Pipeline([\n",
    "        ('sc',StandardScaler()),\n",
    "        ('power_trans',PowerTransformer()),\n",
    "        ('polynom_trans',PolynomialFeatures(degree=2)),\n",
    "        ('rf_clf',rf_gridsearch)\n",
    "        ])\n",
    "print(pipe_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  24 out of  36 | elapsed:    3.9s remaining:    1.9s\n",
      "[Parallel(n_jobs=16)]: Done  36 out of  36 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score is: 0.8622222222222222\n",
      "precision score is: 0.8695652173913043\n",
      "recall score is: 0.8620689655172413\n",
      "auc: 0.8622271433090793\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "warnings.filterwarnings('ignore')\n",
    "pipe_clf.fit(x_train,y_train)\n",
    "y_predict = pipe_clf.predict(x_test)\n",
    "print(f'accuracy score is: {accuracy_score(y_test,y_predict)}')\n",
    "print(f'precision score is: {precision_score(y_test,y_predict)}')\n",
    "print(f'recall score is: {recall_score(y_test,y_predict)}')\n",
    "print(f'auc: {roc_auc_score(y_test,y_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "print(pipe_clf.named_steps['rf_clf'].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
